{% extends "base.html" %}

{% block description %}
An introduction to inertial navigation in marine robotics, from the sensors used to the mathematical tools needed to fuse that sensor data into a navigation solution
{% endblock %}

{% block head %}
<link href="{{ url_for('static', filename='css/inertial_nav.css') }}" rel="stylesheet">
{% endblock %}

{% block content %}
  <div class="row post">
    <div class="col-sm-10 col-sm-offset-1 col-md-8 col-md-offset-2">
      <div class="title-block">
        <p class="date">May 6, 2019</p>
        <h1>Inertial Navigation in Marine Robotics</h1>
        <h2>Or how to know where you robot is when under water</h2>
      </div>
      <div id="body">
        <p>The first thing to know about underwater navigation is that GPS doesn’t work underwater. This simple fact makes figuring out where you are a surprisingly difficult and interesting problem. It turns out that in order to know where you are, you have to know how you got there.</p>
        <p>GPS provides what is called an absolute position reference, which defines our position on planet earth. Due to the lack of an absolute position reference, we need to creatively utilize relative position measurements and tie those measurements to a single or infrequent absolute position measurements, such as a GPS ping when we’re on the surface.</p>
        <p>Inertial navigation is a relative positioning technique that uses of motion and rotation sensors to determine position and orientation. A classic inertial navigation system (INS) is composed of an accelerometer, a magnetometer, and a gyroscope along with a computer to process the sensor data. The data from these sensors are inputs in an application whose output is called a navigation solution.</p>
        <h2>Navigation Solution</h2>
        <p>Our ultimate goal is a navigation solution that includes our robot's pose (position and orientation).</p>
        <pre>
navigation_solution {
  time

  position[3] // x, y, z
  velocity[3]
  acceleration[3]

  attitude[3] // roll, pitch, heading
  attitude_velocity[3]
  attitude_acceleration[3]

  absolute_position[2] // lat, lon
}
        </pre>
        <p>For position we've got 3 spatial dimensions, X, Y, and Z as well the first and second derivatives, velocity and acceleration in each of those 3 dimensions.</p>
        <img
          class="img-responsive"
          alt="Roll, pitch, yaw diagram"
          src="{{ url_for('static', filename='img/roll_pitch_yaw.png') }}"
        />
        <p>Attitude is our measurement of orientation and is composed of roll, pitch, and heading. Roll is the rotation about X, pitch rotation about Y, and heading is rotation about Z.</p>
        <p>Together, position and attitude tell us where our robot is and how it is oriented in the earth frame.</p>

        <h2>Sensors</h2>
        <p>First we'll review the sensors that make up our inertial navigation system.</p>

        <h2>Accelerometer</h2>
        <p>The accelerometer is our only inertial sensor which gives us a measurement of our position. Unfortunately, it is not a very good one.</p>
        <p>To go from acceleration to position we need to integrate twice, which means that any error in our acceleration measurement will increase quadratically over time. Even small errors in acceleration can result in huge errors in position, errors that increase over time.</p>
        <pre>
acceleration =    a
velocity     =  &int; a =     a &middot; t
position     = &int;&int; a = &frac12; &middot; a &middot; t<sup>2</sup></pre>
        <p>Plugging in an accelerometer bias of 0.0196 m/s2 (which is an actual spec from a $20,000 sensor) we would could drift 127 kilometers in an hour while sitting on a bench top:</p>
        <pre>(&frac12;) &middot; 0.0196 meters/second &middot; 3600<sup>2</sup> seconds = 127,008 meters</pre>

        <h3>Magnetometer (AKA Compass)</h3>
        <p>A magnetometer measures the magnetic field in 3 spatial dimensions. A compass is a 1D magnetometer, measuring the magnetic field about Z, giving us our heading.</p>
        <p>Heading is our most important measurement because small errors in heading can lead to large errors in position. The below chart shows the calculated path travelled for a 1 kilometer straight line run given various heading errors.</p>
        <div>
          <svg id="heading_errors"></svg>
        </div>
        <p>The chart illustrates error in final position given various heading errors for a 1km straight line run. If our heading is off by a single degree, we see a positional error of 17 meters, or 1.7% of distance travelled. If our heading is off by 10&deg; that error increases tenfold, to 174 meters, 17% of distance travelled.</p>
        <p>Given these large errors for only a single kilometer of travel, it is obvious that we need to get better heading measurements, but we can only get so far with the compass. Putting a compass in a robot with metal and electricity flowing around it tends to make for unhappy compasses, so we need another sensor to aid in our heading measurements. That’s where the gyroscope comes in.</p>

        <h3>Gyroscope</h3>
        <p>While magnetometers measure changes in angular position, gyroscopes measure changes in angular velocity.</p>
        <p>Velocity is the first derivative of position, so you need to integrate velocity in order to get rotational position. The integral of velocity is <tt>velocity &middot; time</tt>, so our error gets bigger over time, but not nearly as quickly as it does with our accelerometer.</p>
        <pre>
angular velocity =   v
angular position = &int; v  = v &middot; t</pre>
        <p>This is still not as nice as having a direct measurement of angular position, which doesn’t have an error that increases over time, but the gyroscope is a much more precise measurement than the magnetometer, so it turns out to be extremely useful.</p>
        <p>Classic gyroscopes, the kind you might remember from physics class, are spinning masses that measure changes in angular momentum. Modern gyroscopes are a bit more sophisticated but easier to understand. Today’s state-of-the-art gyroscope is the fiber optic gyroscope (FOG) and rather than using conservation of angular momentum, it uses special relativity to calculate rotational velocity.</p>
        <p>Here’s an illustration demonstrating how they work:</p>
        <div>
          <img
            class="img-responsive"
            alt="Demonstration of fiber optic gyro ring stationary and rotating"
            src="../static/img/FOG.png"/>
        </div>
        <p>A laser gets shot around a ring in two directions. The image on the left shows a stationary ring (black) with the two beams of the laser (red and blue) arriving back at the origin at the same time. The image on the right shows a ring rotating clockwise. The beam traveling clockwise (blue) has to travel further than the beam traveling counter-clockwise (red) to get back to where it started, resulting in a different interference pattern in a sensor at the origin. This interference pattern is used to derive the angular velocity along the plane of the ring.</p>
        <p>FOGs are composed of three orthogonal rings and so can measure angular velocity about any axis.</p>
        <p>Given that we still need to integrate once to get angular position, gyroscopes will need to be much more precise than magnetometers to outperform them. The good news is that they are.</p>
        <div>
          TODO: ad plot of gyro errors
        </div>
        <p>The above plot shows the effect of gyro bias values on a 1km straight line run traveling at X m/s. Since the error introduced by the gyroscope increases over time, at some point it will be worse than the magnetometer error. In practice we are able to combine measurements from the magnetometer and aiding sensors enabling the gyroscope to become one of our most valuable sensors.</p>

        <h3>Doppler Velocity Log (DVL)</h3>
        <p>In marine robotics, we are often operating at or near the bottom. When this is the case we can use a DVL to tell us how fast and in what direction we are moving by bouncing sound waves off of the bottom.</p>
        <div>
          <img class="img-responsive" src="../../static/img/dvl_doppler_shift.jpg" />
        </div>
        <p>As the name indicates, the Doppler Velocity Log utilizes the doppler shift to calculate its measurements. The doppler shift is demonstrated by the animation below. The gist is that given a wave of constant frequency, you’ll experience the wave at a higher frequency when you’re moving toward the source compared to when you’re moving away from the source.</p>
        <div>
          <img class="img-responsive" src="../../static/img/Dopplerfrequency.gif" />
        </div>
        <p>The DVL operates by sending a 4-beam signal out of a transducer and then listening for the response. It then measures the phase shift across those 4 beams and reports a velocity and a course-over-ground.</p>
        <p>Course-over-ground is a direct measurement of relative heading and a pretty good one. It can’t tell us which way is north, but it is very valuable in telling us how far we’ve turned.</p>
        <p>The DVL along with our gyroscope, are our two most valuable sensors in smaller vehicles in marine robotics. The effective range of the DVL is from less than a meter to around 150 meters off the bottom.</p>

        <h3>Ultra Short Baseline (USBL)</h3>
        <p>The USBL is another acoustic instrument but unlike any of the other sensors discussed so far, it is able to provide an absolute position reference, however, it requires a second vessel on the surface (with a GPS connection) to do so.</p>
        <p>A USBL system involves a transceiver on a ship, which sends out a ping to a listening remotely-operated-vehicle (ROV). The ROV has a transponder that receives that signal and responds with a signal of its own which is then received by the transceiver back on the ship. This transceiver is composed of a transducer array of at least 3 nodes arranged in a triangle. The ship is able to use the time from initial ping to the time of the response to calculate the distance between ship and ROV and the timing difference between transducers to determine direction to the ROV). This data combined with the GPS position of the ship gives an ROV pilot operating on the ship the absolute position of the vehicle.</p>

        <h3>GPS</h3>
        <p>Though we don’t have GPS while we’re underwater, it is still an important aiding sensor. Most vehicles have a GPS on top so that when they’re on the surface they can get an absolute position fix. When the vehicle submerges it is able to calculate relative position from this absolute reference giving it an idea of its absolute position in the world.</p>

        <h2>Handling Sensor Data</h2>
        <p>So far I’ve described most of the navigation sensors in a typical ROV, but the challenge for the roboticist comes in combining all of that data to get the most accurate solution possible.</p>
        
        <h3>Noise</h3>
        <p>We’ve got our suite of sensors and we know how we’ll use them, but now we need to jam them all together inside of a tiny vehicle with spinning metal, flowing electricity, and other talking sensors. Now we’ve got acoustic noise (DVL, sonar, and USBL all ping), mechanical noise (motors and power converters), electrical noise (both faults and expected), and even temperature effects. Now our expensive sensors with their lovely spec sheets are performing nowhere near how they perform on the bench top.</p>
        <p>A large part in designing and maintaining a robotic system involves reducing noise, to the extent that this is possible. This is an art, honed over years of experience. Characterizing the noise is the first step in the process and iterating on system design is often the end result. But even in the best designed system there will always be noise.</p>
        <p>Fortunately the same mathematical tool that we’ll use to fuse sensor data, also helps us mitigate noise, the Kalman filter.</p>
        <h3>Kalman Filters</h3>
        <p>The Kalman filter is the main tool in our toolbelt for taking this disparate and noisy data and turning it into a navigation solution. Kalman filters are an entire subject in themselves and that is a blog post I plan on writing someday, but this is not that post.</p>
        <p>The Kalman filter is a state estimator that allows us to make predictions based on latest measurements and predicted values, resulting in an estimate that is better than either.</p>
        <div>
          <img 
            class="img-responsive"
            alt="Kalman filter explanation"
            src="../../static/img/kalman_filter.png"
          />
          <p class="caption">Source: <a href="https://www.mathworks.com/videos/understanding-kalman-filters-part-1-why-use-kalman-filters--1485813028675.html">Mathworks</a>
        </div>

        <p>The art of the kalman filter lies in tuning the gains to weight prediction and measurement variances based on what’s happening in the system.</p>
        <p>A simple kalman filter might only include inputs, that is, sensor data. If we consider a single measurement, say heading, our measurement is the most direct reading we have, which we get from the magnetometer. Then our prediction is the higher order reading, coming from the gyroscope. In an ideal scenario, the variance from these sensors becomes the gains of the Kalman filter, though as discussed above there are many sources of noise that we need to account for so this is generally not true in practice.</p>
        <p>A more complex Kalman filter would include vehicle control data, such as thruster effort and direction. This data would be incorporated in the prediction. Using vehicle output data can be difficult though. For example, in a strong current we might need to have thrusters spinning just to hold our position. In that case we’d want to penalize the prediction by giving it a higher variance (resulting in a wider curve in the above image). This would bias our state estimate towards our measurement.</p>
        <p>In practice, each of the values in our navigation solution might have one or more Kalman filter associated with it.</p>

        <h2>Pulling It All Together</h2>
        <p>Finally, thanks to some ingenious sensors and clever math, we end up with a solution that is surprisingly good, given the challenges of the environment and the limitations of the technology.</p>
        <pre>
  navigation_solution {
  time

  position[3]
  velocity[3]
  acceleration[3]

  attitude[3]  
  attitude_velocity[3]
  attitude_acceleration[3]

  absolute_position[2]
  }
        </pre>
        <p>I hope you enjoyed this post. If you’re interested in more content like this, including a more detailed explanation of kalman filters, you should <a href="//twitter.com/mattparrilla">follow me on twitter</a> or <a href="http://matthewparrilla.com">check out my website.</a></p>
        <p>And if you think these sound like fun problems to work on, <a href="//greensea.com/join-our-team">come work with me.</a></p>
      </div>
      {% include "other-stuff.html" %}
    </div>
  </div>
{% endblock %}

{% block scripts %}
<script type="text/javascript" src="{{ url_for('static', filename='js/d3.min.js') }}"></script>
<script type="text/javascript" src="{{ url_for('static', filename='js/inertial_plots.js') }}"></script>
{% endblock %}
